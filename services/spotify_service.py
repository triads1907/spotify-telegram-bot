"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–æ Spotify —Å—Å—ã–ª–∫–∞–º–∏ –ë–ï–ó API
–ü—Ä–æ—Å—Ç–æ–π –ø–æ–¥—Ö–æ–¥: –∏—Å–ø–æ–ª—å–∑—É–µ–º oEmbed –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏—è, YouTube —Å–∞–º –Ω–∞–π–¥—ë—Ç –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—è
"""
import re
from typing import Optional, Dict
import requests


class SpotifyService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ Spotify —Å—Å—ã–ª–æ–∫ –±–µ–∑ API"""
    
    def __init__(self):
        self.session = requests.Session()
        print("‚úÖ Spotify —Å–µ—Ä–≤–∏—Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (oEmbed)")
    
    @staticmethod
    def parse_spotify_url(url: str) -> Optional[Dict[str, str]]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ Spotify URL
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {'type': 'track'|'album'|'playlist', 'id': 'spotify_id'}
        """
        patterns = {
            'track': r'spotify\.com/track/([a-zA-Z0-9]+)',
            'album': r'spotify\.com/album/([a-zA-Z0-9]+)',
            'playlist': r'spotify\.com/playlist/([a-zA-Z0-9]+)',
        }
        
        for content_type, pattern in patterns.items():
            match = re.search(pattern, url)
            if match:
                return {
                    'type': content_type,
                    'id': match.group(1)
                }
        
        return None
    
    def get_track_info_from_url(self, url: str) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–µ–∫–µ –∏–∑ Spotify URL
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç oEmbed API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –∏ –æ–±–ª–æ–∂–∫–∏
        """
        try:
            # –û—á–∏—â–∞–µ–º URL –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            clean_url = url.split('?')[0]
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º oEmbed –¥–ª—è –±–∞–∑–æ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            oembed_url = f"https://open.spotify.com/oembed?url={clean_url}"
            track_name = ""
            image_url = ""
            
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
            }
            
            try:
                response = self.session.get(oembed_url, timeout=5)
                if response.status_code == 200:
                    data = response.json()
                    track_name = data.get('title', '').strip()
                    image_url = data.get('thumbnail_url')
            except Exception as e:
                print(f"‚ö†Ô∏è oEmbed failed, falling back to scraping: {e}")
            
            # –¢–µ–ø–µ—Ä—å –ø–æ–ª—É—á–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ê—Ä—Ç–∏—Å—Ç–∞
            artist_name = ""
            try:
                page_response = self.session.get(clean_url, headers=headers, timeout=5)
                if page_response.status_code == 200:
                    html = page_response.text
                    
                    # –°–ø–æ—Å–æ–± 1: –ò–∑ —Ç–µ–≥–∞ <title>
                    # "Track Name - song and lyrics by Artist | Spotify"
                    title_match = re.search(r'<title>([^<]+)</title>', html)
                    if title_match:
                        title_text = title_match.group(1)
                        if " - song " in title_text and " by " in title_text:
                            artist_part = title_text.split(" by ")[1].split(" | Spotify")[0]
                            artist_name = artist_part.strip()
                            if not track_name:
                                track_name = title_text.split(" - song ")[0].strip()
                    
                    # –°–ø–æ—Å–æ–± 2: –ò–∑ og:description (–µ—Å–ª–∏ 1 –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª)
                    if not artist_name:
                        desc_match = re.search(r'<meta property="og:description" content="([^"]+)"', html)
                        if desc_match:
                            content = desc_match.group(1)
                            # "Artist ¬∑ Song ¬∑ Year"
                            parts = content.split(" ¬∑ ")
                            if len(parts) >= 2:
                                artist_name = parts[0].strip()
                                if not track_name:
                                    track_name = parts[1].strip()
            except Exception as e:
                print(f"‚ö†Ô∏è Scraping failed: {e}")
            
            if track_name:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º ID –∏–∑ URL –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
                parsed = self.parse_spotify_url(clean_url)
                track_id = parsed['id'] if parsed else None
                
                return {
                    'id': track_id,
                    'name': track_name,
                    'artist': artist_name,
                    'image_url': image_url,
                    'spotify_url': clean_url
                }
            
            return None
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Spotify: {e}")
            return None
    
    def get_track_info(self, track_id: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç—Ä–µ–∫–µ –ø–æ ID"""
        url = f"https://open.spotify.com/track/{track_id}"
        info = self.get_track_info_from_url(url)
        if info and not info.get('id'):
            info['id'] = track_id
        return info
    
    async def search_track(self, query: str) -> list:
        """–ê–ª–∏–∞—Å –¥–ª—è –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        return await self.search_tracks(query)

    async def search_tracks(self, query: str) -> list:
        """
        –ü–æ–∏—Å–∫ —Ç—Ä–µ–∫–æ–≤ (–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –±–µ–∑ API)
        –î–ª—è —Ä–∞–±–æ—Ç—ã –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, 
        —Ç–∞–∫ –∫–∞–∫ –ø–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É –±–µ–∑ API –≤ Spotify –∑–∞—Ç—Ä—É–¥–Ω–µ–Ω.
        """
        print(f"‚ö†Ô∏è –ü–æ–∏—Å–∫ –±–µ–∑ Spotify API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {query}")
        return []
    
    def is_playlist_url(self, url: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL —Å—Å—ã–ª–∫–æ–π –Ω–∞ Spotify –ø–ª–µ–π–ª–∏—Å—Ç
        
        Args:
            url: URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            True –µ—Å–ª–∏ —ç—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–ª–µ–π–ª–∏—Å—Ç
        """
        parsed = self.parse_spotify_url(url)
        return parsed is not None and parsed['type'] == 'playlist'
    
    async def get_playlist_info(self, playlist_url: str) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–ª–µ–π–ª–∏—Å—Ç–µ —á–µ—Ä–µ–∑ –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥
        
        Args:
            playlist_url: URL –ø–ª–µ–π–ª–∏—Å—Ç–∞ Spotify
            
        Returns:
            Dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –ø–ª–µ–π–ª–∏—Å—Ç–µ –∏ —Å–ø–∏—Å–∫–æ–º —Ç—Ä–µ–∫–æ–≤
        """
        try:
            from bs4 import BeautifulSoup
            import httpx
            
            # –ü–∞—Ä—Å–∏–º URL –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è ID
            parsed = self.parse_spotify_url(playlist_url)
            if not parsed or parsed['type'] != 'playlist':
                print("‚ùå Invalid playlist URL")
                return None
            
            playlist_id = parsed['id']
            clean_url = f"https://open.spotify.com/playlist/{playlist_id}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            }
            
            print(f"üîç Fetching playlist: {clean_url}")
            
            async with httpx.AsyncClient(headers=headers, follow_redirects=True) as client:
                response = await client.get(clean_url, timeout=30.0)
                
                if response.status_code != 200:
                    print(f"‚ùå Failed to fetch playlist: HTTP {response.status_code}")
                    return None
                
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–ª–µ–π–ª–∏—Å—Ç–∞ –∏–∑ meta tags
                playlist_name = "Unknown Playlist"
                og_title = soup.find('meta', property='og:title')
                if og_title:
                    playlist_name = og_title.get('content', playlist_name)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç—Ä–µ–∫–∏ –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                tracks = []
                script_tag = soup.find('script', {'id': '__NEXT_DATA__', 'type': 'application/json'})
                
                if script_tag:
                    import json
                    data = json.loads(script_tag.string)
                    
                    try:
                        # –ù–∞–≤–∏–≥–∞—Ü–∏—è –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ JSON
                        playlist_data = data.get('props', {}).get('pageProps', {}).get('state', {}).get('data', {}).get('playlistV2', {})
                        
                        if 'content' in playlist_data:
                            items = playlist_data['content'].get('items', [])
                            
                            for idx, item in enumerate(items):
                                try:
                                    track_data = item.get('itemV2', {}).get('data', {})
                                    
                                    if track_data:
                                        track_name = track_data.get('name', 'Unknown')
                                        
                                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏—Å–ø–æ–ª–Ω–∏—Ç–µ–ª–µ–π
                                        artists = track_data.get('artists', {}).get('items', [])
                                        artist_names = [artist.get('profile', {}).get('name', '') for artist in artists]
                                        artist_str = ', '.join(filter(None, artist_names)) or 'Unknown Artist'
                                        
                                        # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                                        duration_ms = track_data.get('trackDuration', {}).get('totalMilliseconds', 0)
                                        duration_sec = duration_ms // 1000
                                        
                                        tracks.append({
                                            'position': idx + 1,
                                            'name': track_name,
                                            'artist': artist_str,
                                            'duration': duration_sec
                                        })
                                        
                                except Exception as e:
                                    print(f"‚ö†Ô∏è  Error parsing track {idx}: {e}")
                                    continue
                    
                    except (KeyError, TypeError, AttributeError) as e:
                        print(f"‚ö†Ô∏è  Error parsing playlist JSON: {e}")
                
                if not tracks:
                    print("‚ö†Ô∏è  Could not extract tracks from playlist")
                    return None
                
                print(f"‚úÖ Found {len(tracks)} tracks in playlist '{playlist_name}'")
                
                return {
                    'id': playlist_id,
                    'name': playlist_name,
                    'url': clean_url,
                    'tracks': tracks,
                    'total_tracks': len(tracks)
                }
                
        except Exception as e:
            print(f"‚ùå Error fetching playlist: {e}")
            import traceback
            traceback.print_exc()
            return None
